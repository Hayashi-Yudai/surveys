|回|ジャンル|github account（敬称略）|link|title||
|:---|:---|:---|:---|:---|:---|
|1|NN一般|takagi|https://arxiv.org/abs/1710.09829|Dynamic Routing Between Capsules|capsule net|
||強化学習|@kmiwa|https://arxiv.org/abs/1803.04675|Using Grouped Linear Prediction and Accelerated Reinforcement Learning for Online Content Caching||
||自然言語 チャットボット|@nharu1san|https://arxiv.org/abs/1612.01627|Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots||
||教育|@kaaztech|https://dl.acm.org/doi/10.1145/3027385.3029479|A neural network approach for students' performance prediction||
||NN一般 活性化|@antimon2|https://arxiv.org/abs/1710.05941|Searching for Activation Functions|swish|
||アノテーション 医療|@exoego|https://arxiv.org/abs/1708.06297|Employing Weak Annotations for Medical Image Analysis Problems||
||量子化|@cohama|https://arxiv.org/abs/1511.00363|BinaryConnect: Training Deep Neural Networks with binary weights during propagations||
||正規化|@melleo1978|https://arxiv.org/abs/1705.08741|Train longer, generalize better: closing the generalization gap in large batch training of neural networks|ghost batch normalization|
||ドメイン適用|@kotamatui|http://papers.nips.cc/paper/6963-joint-distribution-optimal-transportation-for-domain-adaptation.pdf|Joint distribution optimal transportation for domain adaptation||
||物体検出 zero_shot|@n-kats|https://arxiv.org/abs/1803.06049|Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concept||
|2|自然言語|@nharu1san|https://arxiv.org/abs/1802.02614v1|Enhance word representation for out-of-vocabulary on Ubuntu dialogue corpus||
||敵対的事例|@antimon2|https://arxiv.org/abs/1804.00499|Semantic Adversarial Examples||
||強化学習|@kmiwa|https://arxiv.org/abs/1603.00748|Continuous Deep Q-Learning with Model-based Acceleration||
||物体検出|@n-kats|https://arxiv.org/abs/1712.00960|FSSD: Feature Fusion Single Shot Multibox Detector||
||工場|sakurai|https://ieeexplore.ieee.org/document/7864335|A Generic Deep-Learning-Based Approach for Automated Surface Inspection||
|3|半教師|@antimon2|https://arxiv.org/abs/1805.09302|Input and Weight Space Smoothing for Semi-supervised Learning||
||Pruning|@cohama|https://arxiv.org/abs/1805.11394|A novel channel pruning method for deep neural network compression||
||GAN 顔|@yunishimura|https://www.jstage.jst.go.jp/articleke/advpub/0/advpub_TJSKE-D-17-00085/_pdf/-char/ja|Face Image Generation System using Attributes Information with DCGANs|
||学習率スケジューリング|@wkluk-hk|https://arxiv.org/abs/1506.01186v6|Cyclical Learning Rates for Training Neural Networks||
||工場|sakurai|http://journals.sagepub.com/doi/pdf/10.1177/1687814018766682|Intelligent defect classification system based on deep learning||
||3D SLAM|@melleo1978|https://arxiv.org/abs/1803.02286|Learning monocular visual odometry with dense 3D mapping from dense 3D flow||
||強化学習|@kmiwa|https://arxiv.org/abs/1804.00379|Recall Traces: Backtracking Models for Efficient Reinforcement Learning||
||GAN attention|@n-kats|https://arxiv.org/abs/1805.0831|Self-Attention Generative Adversarial Networks|SAGAN||
||自然言語 文書埋め込み|@nharu1san|https://arxiv.org/abs/1803.11175|Universal Sentence Encoder||
|4|トラッキング MOT|@wkluk-hk|https://arxiv.org/abs/1711.02741|Recurrent Autoregressive Networks for Online Multi-Object Tracking|
||GAN|takagi|https://arxiv.org/abs/1702.08431|Boundary-Seeking Generative Adversarial Networks|
||ライブラリ|@cohama|https://arxiv.org/abs/1410.0759|cuDNN: Efficient Primitives for Deep Learning|cuDNN|
||キャプション生成|@Denpa92|https://arxiv.org/abs/1806.04510|Dank Learning: Generating Memes Using Deep Neural Networks|
||自然言語 構文|@nharu1san|http://www.aclweb.org/anthology/P15-1162|Deep Unordered Composition Rivals Syntactic Methods for Text Classification|
||強化学習 関係|@kmiwa|https://arxiv.org/abs/1806.01830|Relational Deep Reinforcement Learning|
||強化学習|@shuuichi|https://arxiv.org/abs/1803.07055|Simple random search provides a competitive approachto reinforcement learning||
||強化学習|@antimon2|https://arxiv.org/abs/1806.00175|Strategic Object Oriented Reinforcement Learning||
||転移学習|sakurai|https://ieeexplore.ieee.org/document/7966162|Transfer Learning for Automated Optical Inspection||
||GAN 音|@hissanova|https://arxiv.org/abs/1802.04208|Synthesizing Audio with Generative Adversarial Networks||
||GAN|@n-kats|https://arxiv.org/abs/1709.01118|WESPE: Weakly Supervised Photo Enhancer for Digital Cameras||
|6|インスタンスセグメンテーション|@wkluk-hk|https://arxiv.org/abs/1807.05361|Non-local RoIs for Instance Segmentation||
||フロー系生成モデル|@antimon2|https://arxiv.org/abs/1807.03039|Glow: Generative Flow with Invertible 1×1 Convolutions|Glow|
||強化学習|@kmiwa|https://arxiv.org/abs/1802.03006|Learning and Querying Fast Generative Models for Reinforcement Learnin||
||ライブラリ|@kencyke|http://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform|TFX: A TensorFlow-Based Production-Scale Machine Learning Platform|TFX|
||NN一般 初期化|@melleo1978|https://arxiv.org/abs/1702.08591|The Shattered Gradients Problem: If resnets are the answer, then what is the question?||
||画像データセット|@yuji38kwmt|https://www.arxiv-vanity.com/papers/1805.04687/|BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling|BDD100K
||グラフ系|@n-kats|https://arxiv.org/abs/1806.01261|Relational inductive biases, deep learning, and graph networks|GN|
||強化学習|@kmiwa|https://arxiv.org/pdf/1707.06203|Imagination-Augmented Agents for Deep Reinforcement Learning|
||自然言語データセット|@nharu1san|https://arxiv.org/abs/1312.3005|One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling||
||転移学習|sakurai|https://arxiv.org/abs/1805.08974|Do Better ImageNet Models Transfer Better ?||
|7|対話|takagi|https://www.jstage.jst.go.jp/article/tjsai/33/1/33_DSH-F/_pdf|Engagement Recognition from Listener’s Behaviors in Spoken Dialogue Using a Latent Character Model||
||蒸留|yasuno|http://export.arxiv.org/pdf/1805.04770|Born Again Neural Networks||
||アノテーション|@yuji38kwmt|https://arxiv.org/abs/1809.08888|Empirical Methodology for Crowdsourcing Ground Truth||
||物体検出|@n-kats|https://arxiv.org/abs/1711.07240|MegDet: A Large Mini-Batch Object Detector|MegDet|
||軽量モデル|@cohama|https://arxiv.org/abs/1807.11164|ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design|ShuffleNet V2|
||NN一般 活性化|@antimon2|https://arxiv.org/abs/1810.01829|Weighted Sigmoid Gate Unit for an Activation Function of Deep Neural Network||
|8|理論 NN一般 初期化|@melleo1978|https://arxiv.org/abs/1806.05393v2|Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks||
||インスタンスセグメンテーション 点群 医療|@wkluk-hk|https://arxiv.org/abs/1811.03208|Deep Semantic Instance Segmentation of Tree-like Structures Using Synthetic Data||
||ライブラリ|@antimon2|https://arxiv.org/abs/1810.09868|Automatic Full Compilation of Julia Programs and ML Models to Cloud TPUs||
||3D|@n-kats|https://arxiv.org/abs/1804.01654|Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images||
||軽量モデル|@cohama|http://openaccess.thecvf.com/content_ECCV_2018/html/Xin_Wang_SkipNet_Learning_Dynamic_ECCV_2018_paper.html|SkipNet: Learning Dynamic Routing in Convolutional Networks||
||画像データセット アノテーション|@yuji38kwmt|https://arxiv.org/abs/1712.08394|The ParallelEye Dataset: Constructing Large-Scale Artificial Scenes for Traffic Vision Research||
||神経科学|@nharu1san|https://arxiv.org/abs/1811.02923|Universal Spike Classifier||
|9|量子化|@melleo1978|https://openreview.net/forum?id=ByfPDyrYim|Linear Backprop in non-linear networks||
||異常検知|@devjap|https://arxiv.org/abs/1703.05921|Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery||
||アノテーション|@yuji38kwmt|https://www.researchgate.net/publication/291249011_Crowdsourcing_annotations_for_visual_object_detection|Crowdsourcing Annotations for Visual Object Detection||
||距離 最適輸送|@n-kats|https://arxiv.org/abs/1811.02834|Fused Gromov-Wasserstein distance for structured objects: theoretical foundations and mathematical properties||
||転移学習|sakurai|https://arxiv.org/abs/1808.01974|A Survey of Deep Transfer Learning||
||NN一般 padding|@antimon2|https://arxiv.org/abs/1811.11718|Partial Convolution based Padding||
||軽量モデル NAS|@cohama|https://arxiv.org/abs/1812.02975|ShuffleNASNets: Efficient CNN models through modified Efficient Neural Architecture Search||
|10|理論 正規化|@melleo1978|https://arxiv.org/abs/1805.11604v3|How Does Batch Normalization Help Optimization?||
||対話|takagi|http://www.cs.toronto.edu/face2face|A face to face neural conversation model||
||蒸留 転移学習|sakurai|https://arxiv.org/abs/1503.02531|Distilling the Knowledge in a Neural Network||
||物体検出|@cohama|https://arxiv.org/abs/1804.06215|DetNet: A Backbone network for Object Detection||
||運転 車線|@yuji38kwmt|https://arxiv.org/abs/1806.05984||Ego-Lane Analysis System (ELAS): Dataset and Algorithms||
||ライブラリ|@antimon2|https://arxiv.org/abs/1812.09064|GaussianProcesses.jl: A Nonparametric Bayes package for the Julia Language|
||3D SLAM|@n-kats|https://arxiv.org/abs/1811.06152|Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos||
|11|GAN|@melleo1978|https://arxiv.org/abs/1812.04948|A Style-Based Generator Architecture for Generative Adversarial Networks|StyleGAN|
||軽量モデル|@cohama|https://arxiv.org/abs/1901.09615|Convolutional Neural Networks with Layer Reuse||
||NAS グラフ系|@n-kats|https://arxiv.org/abs/1808.07233|Neural Architecture Optimization||
||時系列|sakurai|https://arxiv.org/abs/1811.01533|Transfer learning for time series classification||
|12|ライブラリ|@antimon2|https://arxiv.org/abs/1902.02376|DiffEqFlux.jl — A Julia Library for Neural Differential Equations||
||自然言語 質問回答|@nharu1san|https://arxiv.org/abs/1902.01718|End-to-End Open-Domain Question Answering with BERTserini||
||軽量モデル|@cohama|https://arxiv.org/abs/1902.09701|Learning Implicitly Recurrent CNNs Through Parameter Sharing||
|13|GAN 3D|@melleo1978|https://arxiv.org/abs/1904.01326|HoloGAN: Unsupervised learning of 3D representations from natural images|HoloGAN|
||GAN|takagi|https://arxiv.org/abs/1811.10597v2|GAN Dissection: Visualizing and Understanding Generative Adversarial Networks||
||3D SLAM|@n-kats|https://arxiv.org/abs/1904.04998|Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras||
||自然言語 文書分類|@nharu1san|https://arxiv.org/abs/arxiv_1904.08398|DocBERT: BERT for Document Classification||
||物体検出|@cohama|https://arxiv.org/abs/1904.01355v3|FCOS: Fully Convolutional One-Stage Object Detection|FCOS|
||時系列|sakurai|http://www.lumenai.fr/blog/time-series-aggregation|Time series aggregation Comparison of two global averaging approaches||
||運転 車線|@yuji38kwmt|https://arxiv.org/abs/1802.05591|Towards End-to-End Lane Detection: an Instance Segmentation Approach||
|14|NN一般 初期化|@melleo1978|https://arxiv.org/abs/1901.09321|Fixup Initialization: Residual Learning Without Normalization|Fixup|
||自然言語|@nharu1san|https://arxiv.org/abs/1905.05950|BERT Rediscovers the Classical NLP Pipeline||
||物体検出|@cohama|https://arxiv.org/abs/1904.08189|CenterNet: Keypoint Triplets for Object Detection||
||運転|@yuji38kwmt|https://arxiv.org/abs/1904.08980|Exploring the Limitations of Behavior Cloning for Autonomous Driving||
||インスタンスセグメンテーション|@antimon2|https://arxiv.org/abs/1708.02551|Semantic Instance Segmentation with a Discriminative Loss Function||
||3D|@n-kats|https://arxiv.org/abs/1812.03828|Occupancy Networks: Learning 3D Reconstruction in Function Space||
||埋め込み 顔|takagi|https://arxiv.org/abs/1811.11283|A Compact Embedding for Facial Expression Similarity||
|15|半教師|@melleo1978|https://arxiv.org/abs/1904.12848v1|Unsupervised Data Augmentation||
||強化学習|@Mit-Funa|https://deepmind.com/blog/capture-the-flag-science/?utm_source=Deep+Learning+Weekly&utm_campaign=cf75ae36f6-EMAIL_CAMPAIGN_2019_04_24_03_18_COPY_01&utm_medium=email&utm_term=0_384567b42d-cf75ae36f6-73708453|Human-level performance in 3D multiplayer games with populationbased reinforcement learning||
||半教師|@cohama|https://arxiv.org/abs/1905.02249v1|MixMatch: A Holistic Approach to Semi-Supervised Learning|MixMatch|
||自然言語 司法|@nharu1san|https://arxiv.org/abs/1906.02059|Neural Legal Judgment Prediction in English||
||理論|@n-kats|https://arxiv.org/abs/1805.08522|Deep learning generalizes because the parameter-function map is biased towards simple functions||
|16|データオーグメント|@melleo1978|https://arxiv.org/abs/1810.12890|DropBlock: A regularization method for convolutional networks||
||最適化|@Kgm1500|https://arxiv.org/abs/1802.09568|Shampoo: Preconditioned Stochastic Tensor Optimization||
||画風変換|@n-kats|https://arxiv.org/abs/1703.06868|Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization|AdaIN|
||NN一般|@cohama|https://arxiv.org/abs/1703.06211|Deformable Convolutional Networks||
||ライブラリ|@antimon2|https://estadistika.github.io//julia/python/packages/knet/flux/tensorflow/machine-learning/deep-learning/2019/06/20/Deep-Learning-Exploring-High-Level-APIs-of-Knet.jl-and-Flux.jl-in-comparison-to-Tensorflow-Keras.html|Deep Learning: Exploring High Level APIs of Knet.jl and Flux.jl in comparison to Tensorflow-Keras||
||強化学習環境|@Mit-Funa|https://ai.googleblog.com/2019/06/introducing-google-research-football.html|Google Research Football: A Novel Reinforcement Learning Environment|
|17|最適化|@melleo1978|https://arxiv.org/abs/1905.11286|Stochastic Gradient Methods with Layer-wise Adaptive Moments for Training of Deep Networks|NovoGrad|
||自己教師 optical_flow|@n-kats|https://arxiv.org/abs/1904.09117|SelFlow: Self-Supervised Learning of Optical Flow||
||自己教師 トラッキング|@cohama|https://arxiv.org/abs/1806.09594|Tracking Emerges by Colorizing Videos||
|18|attention|@melleo1978|https://arxiv.org/abs/1906.05909|Stand-Alone Self-Attention in Vision Models||
||物体検出|@cohama|https://arxiv.org/abs/1909.03625|CBNet: A Novel Composite Backbone Network Architecture for Object Detection||
||グラフ系 物理|@n-kats|https://arxiv.org/abs/1909.02487|Ab-Initio Solution of the Many-Electron Schrödinger Equation with Deep Neural Networks|FermiNet|
||ライブラリ|@antimon2|https://dl.acm.org/inst_page.cfm?id=60022195|Gen: A General-Purpose Probabilistic Programming System with Programmable Inference||
||グラフ系 物理|@yuji38kwmt|https://arxiv.org/abs/1906.10033|Unifying machine learning and quantum chemistry – a deep neural network for molecular wavefunctions||
|19|tutorial|@FunabikiKeisuke|https://arxiv.org/abs/1909.13739|https://www.programiz.com/python-programming|
||フロー系生成 グラフ系 物理|@n-kats|https://arxiv.org/abs/1909.13739|Equivariant Hamiltonian Flows||
|20|contrastive_learning|@melleo1978|https://arxiv.org/abs/1911.05722v2|Momentum Contrast for Unsupervised Visual Representation Learning|MoCo|
||異常検知|@wkluk-hk|https://arxiv.org/abs/1802.06222|Efficient GAN-Based Anomaly Detection||
||自然言語|@nharu1san|https://arxiv.org/abs/1910.13461|BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension||
||動画生成 姿勢|@n-kats|https://arxiv.org/abs/1910.12713|Few-shot Video-to-Video Synthesis||
||アノテーション|@yuji38kwmt|https://arxiv.org/abs/1911.02807|Improving Human Annotation in Single Object Tracking||
||物体検出|@cohama|https://arxiv.org/abs/1901.01892|Scale-Aware Trident Networks for Object Detection||
|21|GAN|@melleo1978|https://arxiv.org/abs/1912.04958|Analyzing and Improving the Image Quality of StyleGAN|StyleGAN2|
||NAS|@wkluk-hk|https://arxiv.org/abs/1807.11626|MnasNet: Platform-Aware Neural Architecture Search for Mobile|MNAS|
||強化学習|@Mit-Funa|https://arxiv.org/abs/1912.00167|IMPACT: Importance Weighted Asynchronous Architectures with Clipped Target Networks||
||検索|@yuji38kwmt|https://arxiv.org/abs/1903.04638|Challenges in Search on Streaming Services: Netflix Case Study||
||NN一般|@n-kats|https://arxiv.org/abs/1905.11786|Putting An End to End-to-End: Gradient-Isolated Learning of Representations|GIM|
||ライブラリ SLAM|@nharu1san|https://arxiv.org/abs/1910.01122|OpenVSLAM: A Versatile Visual SLAM Framework|OpenVSLAM|
||ライブラリ|@cohama|https://www.atmarkit.co.jp/ait/articles/1910/31/news028.html|PyTorch vs. TensorFlow||
|22|画像データセット アノテーション 運転 キャプション|@melleo1978|https://arxiv.org/abs/1807.11546|Textual Explanations for Self-Driving Vehicles|BDD-X|
||データ 転移学習|@wkluk-hk|https://arxiv.org/abs/2001.02799|Neural Data Server: A Large-Scale Search Engine for Transfer Learning Data||
||3D|@antimon2|https://arxiv.org/abs/2001.05422|Indoor Layout Estimation by 2D LiDAR and Camera Fusion||
||強化学習|@n-kats|https://arxiv.org/abs/1911.08265|Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model|MuZero|
||ライブラリ エッジ|@Mit-Funa|https://github.com/NNgen/nngen|NNgen||
|23|contrastive_learning|@melleo1978|https://arxiv.org/abs/2002.05709|A Simple Framework for Contrastive Learning of Visual Representations|SimCLR|
||セグメンテーション|@FunabikiKeisuke|http://mprg.jp/data/MPRG/F_group/F20191205_goto.pdf|カメラ間の整合性を考慮した全周囲画像のセグメンテーション||
||強化学習|@Mit-Funa|https://arxiv.org/abs/1806.06923|Implicit Quantile Networks for Distributional Reinforcement Learning||
||アノテーション|@yuji38kwmt|https://arxiv.org/abs/2002.06626|Block Annotation: Better Image Annotation for Semantic Segmentation with Sub-Image Decomposition|
||理論 蒸留|@n-kats|https://arxiv.org/abs/2002.05715|Self-Distillation Amplifies Regularization in Hilbert Space||
||物体検出|@cohama|https://arxiv.org/abs/1911.12451v3|Empirical Upper Bound in Object Detection and More||
|24|3D SLAM|@melleo1978|https://arxiv.org/abs/2002.05709|Unsupervised Learning of Depth, Optical Flow and Pose with Occlusion from 3D Geometry||
||強化学習 world_model|@Mit-Funa|https://ai.googleblog.com/2020/03/introducing-dreamer-scalable.html?m=1|Introducing Dreamer: Scalable Reinforcement Learning Using World Models||
||物体検出 レア事例|@cohama|https://arxiv.org/abs/2003.05176|Equalization Loss for Long-Tailed Object Recognition||
||NN一般 正規化|@n-kats|https://arxiv.org/abs/2002.10444|Batch Normalization Biases Deep Residual Networks Towards Shallow Paths|Skip init|
|25|3D|@strshp|https://drive.google.com/file/d/17ki_YAL1k5CaHHP3pIBFWvw-ztF4CCPP/view|3D Photography using Context-aware Layered Depth Inpainting||
||高速化|@melleo1978|https://arxiv.org/abs/1903.03129v2|SLIDE : IN DEFENSE OF SMART ALGORITHMS OVER HARDWARE ACCELERATION FOR LARGE-SCALE DEEP LEARNING SYSTEMS|SLIDE|
||VAE|@sennin0901|https://arxiv.org/abs/1906.00446|Generating Diverse High-Fidelity Images with VQ-VAE-2|VQ-VAE-2|
||3D グラフ系 点群 インスタンスセグメンテーション|@n-kats|https://arxiv.org/abs/2003.13867|3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation||
||NN一般 軽量モデル|@cohama|https://arxiv.org/abs/2003.13549v2|Rethinking Depthwise Separable Convolutions: How Intra-Kernel Correlations Lead to Improved MobileNets|BSConv|
||アノテーション|@usakotail|https://www.arxiv-vanity.com/papers/1909.12493/|Invisible Marker:Automatic Annotation for Object Manipulation||
|26|GAN 姿勢|@strshp|https://menyifang.github.io/projects/ADGAN/ADGAN_files/Paper_ADGAN_CVPR2020.pdf|Controllable Person Image Synthesis with Attribute-Decomposed GAN||
||GAN auto_encoder|@sennin0901|https://arxiv.org/abs/2004.04467|Adversarial Latent Autoencoders||
||最適化|@melleo1978|https://arxiv.org/abs/2001.06782v2|Gradient Surgery for Multi-Task Learning||
||contrastive_learning world_model|@n-kats|https://arxiv.org/abs/1911.12247|Contrastive Learning of Structured World Models|C-SWM|
||NN一般 正規化|@cohama|https://arxiv.org/abs/1905.11926v4|Network Deconvolution||
||物体検出|@usakotail|https://arxiv.org/abs/2004.10934|YOLOv4: Optimal Speed and Accuracy of Object Detection|YOLOv4|
